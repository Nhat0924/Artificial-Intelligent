{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# must run first in order to access the files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyFYk4BdBHGX",
        "outputId": "9a08b11a-d57e-4f19-a314-9deddf9827d9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Project 1\n",
        "Nhat Nguyen\n",
        "Date: 2-1-2024\n",
        "\n",
        "Bread-First Search Report\n",
        "\n",
        "Design:\n",
        "*   To traverse the nodes level by level in an uninformed order, I design a Breadth-First Search algorithm that will enqueue each node and check for any edge between that node to any other node, dequeue that node and mark it visited, and continuously do so to its adjacent nodes until the goal node has been reached. All of the visited nodes will be added to an output list to display the path that it takes to find the goal node.\n",
        "\n",
        "Implementation:\n",
        "*   In this implementation of Breadth-First Search(BFS), I decided to use a queue as the default data structure for the search. The reason for this is because queue have a First In First Out principle that allow traversal by level and is fairly common to use for BFS implementation.\n",
        "\n",
        "*   First, I use defaultdict subclass with a list parameter to create a dictionary of list (formally known as adjacency list) that will be use to add the edge between to node. Then, for each node value I can assign a key list of adjacent nodes as edge to that node\n",
        "\n",
        "*   Then, for the BFS algorithm, I initialize three empty array: a queue, a visit, and an output array. The visit array will be filled with False to indicate that no node has been visited yet. I will then enqueue the first node into the queue array, marked it as True in the visit array, then enqueue each of the edge associated with this node, and finally dequeue the node into the output array for path display later.\n",
        "\n",
        "*   I iterate this process with a while loop until either the queue array no longer have the next node or until the goal node has been reached, in which case it will return.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dHiUCEQF_xsn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STO-Pl6cvdqw",
        "outputId": "5af1d322-75b6-4182-eba9-23a6d2fedb55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BFS: ['N_0', 'N_1', 'N_100', 'N_2', 'N_200', 'N_102', 'N_300', 'N_201', 'N_400', 'N_301', 'N_101', 'N_202', 'N_500', 'N_401', 'N_302', 'N_501', 'N_600', 'N_402', 'N_502', 'N_602', 'N_601', 'N_603', 'N_503', 'N_703', 'N_604', 'N_504', 'N_403', 'N_803', 'N_704', 'N_605', 'N_404', 'N_303', 'N_802', 'N_903', 'N_804', 'N_705', 'N_304', 'N_203', 'N_902', 'N_801', 'N_904', 'N_805', 'N_706', 'N_204', 'N_901', 'N_800', 'N_905', 'N_806', 'N_205', 'N_900', 'N_700', 'N_906', 'N_305', 'N_206', 'N_701', 'N_306', 'N_207', 'N_702', 'N_406', 'N_107', 'N_307', 'N_405', 'N_506', 'N_407', 'N_108', 'N_106', 'N_7', 'N_505', 'N_606', 'N_208', 'N_8', 'N_109', 'N_6', 'N_105', 'N_607', 'N_209', 'N_308', 'N_9', 'N_110', 'N_5', 'N_707', 'N_608', 'N_309', 'N_10', 'N_111', 'N_210', 'N_4', 'N_807', 'N_708', 'N_609', 'N_310', 'N_11', 'N_112', 'N_3', 'N_808', 'N_709', 'N_610', 'N_311', 'N_410', 'N_12', 'N_212', 'N_103', 'N_908', 'N_809', 'N_611', 'N_211', 'N_312', 'N_409', 'N_510', 'N_213', 'N_104', 'N_909', 'N_907', 'N_810', 'N_711', 'N_412', 'N_509', 'N_511', 'N_113', 'N_313', 'N_910', 'N_712', 'N_710', 'N_811', 'N_411', 'N_508', 'N_114', 'N_413', 'N_713', 'N_812', 'N_911', 'N_507', 'N_408', 'N_14', 'N_115', 'N_513', 'N_813', 'N_912', 'N_13', 'N_15', 'N_116', 'N_215', 'N_512', 'N_514', 'N_613', 'N_913', 'N_117', 'N_315', 'N_216', 'N_612', 'N_614', 'N_914', 'N_217', 'N_17', 'N_415', 'N_316', 'N_714', 'N_218', 'N_317', 'N_16', 'N_18', 'N_414', 'N_416', 'N_715', 'N_814', 'N_318', 'N_118', 'N_19', 'N_314', 'N_417', 'N_516', 'N_716', 'N_815', 'N_418', 'N_119', 'N_20', 'N_214', 'N_616', 'N_915', 'N_816', 'N_419', 'N_518', 'N_21', 'N_615', 'N_617', 'N_916', 'N_817', 'N_519', 'N_420', 'N_121', 'N_22', 'N_515', 'N_517', 'N_717', 'N_618', 'N_917', 'N_122', 'N_120', 'N_23', 'N_718', 'N_619', 'N_222', 'N_123', 'N_220', 'N_24', 'N_719', 'N_221', 'N_322', 'N_223', 'N_124', 'N_219', 'N_720', 'N_819', 'N_321', 'N_323', 'N_125', 'N_224', 'N_319', 'N_721', 'N_820', 'N_818', 'N_421', 'N_324', 'N_423', 'N_225', 'N_25', 'N_320', 'N_722', 'N_821', 'N_920', 'N_918', 'N_325', 'N_424', 'N_422', 'N_226', 'N_26', 'N_921', 'N_919', 'N_524', 'N_425', 'N_522', 'N_126', 'N_326', 'N_27', 'N_523', 'N_525', 'N_426', 'N_622', 'N_521', 'N_127', 'N_327', 'N_625', 'N_520', 'N_227', 'N_427', 'N_624', 'N_725', 'N_620', 'N_228', 'N_428', 'N_527', 'N_623', 'N_621', 'N_128', 'N_328', 'N_528', 'N_526', 'N_129', 'N_626', 'N_229', 'N_130', 'N_29', 'N_329', 'N_230', 'N_131', 'N_30', 'N_28', 'N_231', 'N_330', 'N_132', 'N_31', 'N_430', 'N_331', 'N_32', 'N_429', 'N_332', 'N_33', 'N_529', 'N_232', 'N_333', 'N_432', 'N_133', 'N_629', 'N_233', 'N_433', 'N_431', 'N_532', 'N_630', 'N_628', 'N_234', 'N_533', 'N_434', 'N_531', 'N_631', 'N_730', 'N_627', 'N_728', 'N_235', 'N_134', 'N_633', 'N_534', 'N_435', 'N_334', 'N_530', 'N_731', 'N_830', 'N_727', 'N_828', 'N_135', 'N_34', 'N_632', 'N_535', 'N_634', 'N_831', 'N_827', 'N_35', 'N_635', 'N_734', 'N_927', 'N_826', 'N_36', 'N_636', 'N_735', 'N_834', 'N_733', 'N_926', 'N_928', 'N_726', 'N_37', 'N_736', 'N_536', 'N_637', 'N_835', 'N_833', 'N_732', 'N_925', 'N_38', 'N_436', 'N_737', 'N_836', 'N_935', 'N_832', 'N_933', 'N_825', 'N_138', 'N_39', 'N_336', 'N_837', 'N_738', 'N_934', 'N_932', 'N_824', 'N_139', 'N_236', 'N_335', 'N_937', 'N_638', 'N_838', 'N_931', 'N_924', 'N_724', 'N_239', 'N_140', 'N_237', 'N_136', 'N_936', 'N_538', 'N_639', 'N_930', 'N_723', 'N_238', 'N_339', 'N_40', 'N_240', 'N_337', 'N_137', 'N_537', 'N_739', 'N_929', 'N_823', 'N_338', 'N_340', 'N_41', 'N_437', 'N_829', 'N_822', 'N_923', 'N_341', 'N_141', 'N_42', 'N_438', 'N_729', 'N_922', 'N_241', 'N_142', 'N_43', 'N_439', 'N_242', 'N_143', 'N_44', 'N_440', 'N_539', 'N_243', 'N_342', 'N_244', 'N_343', 'N_144', 'N_245', 'N_443', 'N_145', 'N_543', 'N_442', 'N_45', 'N_544', 'N_441', 'N_46', 'N_444', 'N_545', 'N_541', 'N_146', 'N_47', 'N_344', 'N_546', 'N_645', 'N_445', 'N_542', 'N_540', 'N_641', 'N_147', 'N_246', 'N_48', 'N_345', 'N_547', 'N_644', 'N_646', 'N_642', 'N_640', 'N_741', 'N_148', 'N_49', 'N_346', 'N_647', 'N_744', 'N_643', 'N_740', 'N_742', 'N_149', 'N_347', 'N_446', 'N_747', 'N_745', 'N_840', 'N_842', 'N_249', 'N_150', 'N_247', 'N_447', 'N_748', 'N_746', 'N_839', 'N_940', 'N_843', 'N_841', 'N_248', 'N_349', 'N_250', 'N_151', 'N_448', 'N_648', 'N_846', 'N_939', 'N_743', 'N_943', 'N_941', 'N_348', 'N_449', 'N_350', 'N_51', 'N_548', 'N_845', 'N_946', 'N_847', 'N_938', 'N_942', 'N_450', 'N_50', 'N_844', 'N_947', 'N_848', 'N_550', 'N_944', 'N_948', 'N_549', 'N_650', 'N_551', 'N_945', 'N_949', 'N_649', 'N_750', 'N_651', 'N_451', 'N_950', 'N_749', 'N_751', 'N_351', 'N_849', 'N_851', 'N_352', 'N_251', 'N_951', 'N_850', 'N_252', 'N_952', 'N_253', 'N_152', 'N_153', 'N_52', 'N_53', 'N_54', 'N_55', 'N_154', 'N_155', 'N_56', 'N_254', 'N_156', 'N_57', 'N_354', 'N_255', 'N_256', 'N_157', 'N_58', 'N_353', 'N_355', 'N_356', 'N_158', 'N_453', 'N_456', 'N_357', 'N_159', 'N_452', 'N_455', 'N_556', 'N_257', 'N_457', 'N_59', 'N_259', 'N_160', 'N_552', 'N_454', 'N_557', 'N_555', 'N_60', 'N_258', 'N_260', 'N_553', 'N_652', 'N_657', 'N_655', 'N_61', 'N_358', 'N_261', 'N_554', 'N_752', 'N_653', 'N_757', 'N_658', 'N_755', 'N_656', 'N_654', 'N_62', 'N_359', 'N_852', 'N_754', 'N_855', 'N_756', 'N_162', 'N_853', 'N_854', 'N_753', 'N_955', 'N_856', 'N_161', 'N_262', 'N_163', 'N_953', 'N_956', 'N_857', 'N_164', 'N_263', 'N_63', 'N_954', 'N_957', 'N_165', 'N_264', 'N_363', 'N_65', 'N_364', 'N_463', 'N_64', 'N_66', 'N_563', 'N_464', 'N_67', 'N_166', 'N_562', 'N_564', 'N_465', 'N_167', 'N_68', 'N_266', 'N_662', 'N_561', 'N_267', 'N_168', 'N_366', 'N_762', 'N_663', 'N_661', 'N_367', 'N_169', 'N_268', 'N_365', 'N_862', 'N_761', 'N_763', 'N_664', 'N_660', 'N_69', 'N_368', 'N_265', 'N_962', 'N_764', 'N_665', 'N_760', 'N_560', 'N_70', 'N_369', 'N_864', 'N_765', 'N_860', 'N_170', 'N_71', 'N_269', 'N_370', 'N_469', 'N_964', 'N_863', 'N_865', 'N_766', 'N_859', 'N_861', 'N_960', 'N_72', 'N_171', 'N_470', 'N_371', 'N_468', 'N_569', 'N_963', 'N_767', 'N_866', 'N_759', 'N_959', 'N_961', 'N_172', 'N_73', 'N_271', 'N_467', 'N_570', 'N_768', 'N_966', 'N_867', 'N_758', 'N_659', 'N_958', 'N_173', 'N_272', 'N_74', 'N_270', 'N_567', 'N_466', 'N_668', 'N_868', 'N_965', 'N_967', 'N_858', 'N_559', 'N_273', 'N_372', 'N_75', 'N_174', 'N_568', 'N_566', 'N_968', 'N_459', 'N_558', 'N_373', 'N_472', 'N_76', 'N_175', 'N_565', 'N_666', 'N_460', 'N_458', 'N_473', 'N_471', 'N_77', 'N_176', 'N_275', 'N_667', 'N_461', 'N_360', 'N_571', 'N_177', 'N_274', 'N_276', 'N_462', 'N_361', 'N_572', 'N_277', 'N_374', 'N_362', 'N_672', 'N_377', 'N_278', 'N_474', 'N_375', 'N_671', 'N_673', 'N_376', 'N_378', 'N_178', 'N_574', 'N_771', 'N_670', 'N_476', 'N_78', 'N_179', 'N_575', 'N_573', 'N_772', 'N_871', 'N_770', 'N_477', 'N_279', 'N_79', 'N_180', 'N_675', 'N_576', 'N_475', 'N_773', 'N_971', 'N_870', 'N_769', 'N_577', 'N_80', 'N_181', 'N_674', 'N_676', 'N_972', 'N_970', 'N_869', 'N_669', 'N_677', 'N_578', 'N_81', 'N_774', 'N_969', 'N_678', 'N_478', 'N_579', 'N_82', 'N_775', 'N_679', 'N_580', 'N_875', 'N_680', 'N_480', 'N_874', 'N_681', 'N_380', 'N_479', 'N_873', 'N_974', 'N_682', 'N_280', 'N_379', 'N_872', 'N_973', 'N_582', 'N_281', 'N_581', 'N_482', 'N_381', 'N_282', 'N_382', 'N_481', 'N_283', 'N_383', 'N_284', 'N_183', 'N_384', 'N_184', 'N_83', 'N_182', 'N_484', 'N_84', 'N_483', 'N_485', 'N_85', 'N_583', 'N_486', 'N_585', 'N_185', 'N_586', 'N_584', 'N_685', 'N_186', 'N_686', 'N_684', 'N_785', 'N_286', 'N_86', 'N_786', 'N_687', 'N_784', 'N_683', 'N_285', 'N_287', 'N_386', 'N_886', 'N_688', 'N_587', 'N_783', 'N_385', 'N_187', 'N_887', 'N_788', 'N_487', 'N_883', 'N_782', 'N_87', 'N_787', 'N_789', 'N_888', 'N_387', 'N_884', 'N_781', 'N_882', 'N_88', 'N_689', 'N_790', 'N_988', 'N_889', 'N_984', 'N_885', 'N_780', 'N_881', 'N_982', 'N_188', 'N_89', 'N_589', 'N_890', 'N_791', 'N_989', 'N_985', 'N_779', 'N_983', 'N_288', 'N_90', 'N_189', 'N_990', 'N_691', 'N_986', 'N_778', 'N_879', 'N_289', 'N_388', 'N_91', 'N_190', 'N_692', 'N_591', 'N_987', 'N_777', 'N_878', 'N_880', 'N_389', 'N_488', 'N_92', 'N_290', 'N_191', 'N_792', 'N_693', 'N_590', 'N_877', 'N_489', 'N_588', 'N_93', 'N_192', 'N_291', 'N_892', 'N_694', 'N_593', 'N_690', 'N_876', 'N_490', 'N_94', 'N_193', 'N_292', 'N_391', 'N_893', 'N_992', 'N_594', 'N_794', 'N_776', 'N_976', 'N_390', 'N_95', 'N_194', 'N_293', 'N_392', 'N_491', 'N_793', 'N_991', 'N_993', 'N_795', 'N_894', 'N_977', 'N_975', 'N_96', 'N_195', 'N_492', 'N_393', 'N_891', 'N_994', 'N_796', 'N_695', 'N_978', 'N_97', 'N_196', 'N_592', 'N_493', 'N_995', 'N_797', 'N_896', 'N_595', 'N_696', 'N_979', 'N_197', 'N_296', 'N_996', 'N_895', 'N_897', 'N_495', 'N_697', 'N_980', 'N_198', 'N_997', 'N_698', 'N_981', 'N_98', 'N_298', 'N_998', 'N_699', 'N_798', 'N_99', 'N_999']\n",
            "Length: 977\n",
            "Elapse time: 0.0015869140625 seconds\n"
          ]
        }
      ],
      "source": [
        "# Nhat Nguyen\n",
        "# 2-1-2024\n",
        "\n",
        "# Breadth-first search implementation using queue\n",
        "import time\n",
        "from collections import defaultdict\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "#class BFS - Breadth-first search\n",
        "class BFS:\n",
        "  def __init__(self):\n",
        "    # default dictionary to store the graph info\n",
        "    self.adjacent = defaultdict(list)\n",
        "\n",
        "   # A readEdge function that reads in the edges from the edge list along with the weight as input\n",
        "  def readEdge(self, fname):\n",
        "    file = open(fname, 'r')\n",
        "\n",
        "    for line in file:\n",
        "        vertex = line.strip().split(',')\n",
        "        v1, v2, w = int(vertex[0].removeprefix('N_')), int(vertex[1].removeprefix('N_')), float(vertex[2])\n",
        "        self.addEdge(v1, v2, w)\n",
        "\n",
        "    file.close()\n",
        "\n",
        "    # add edge function\n",
        "  def addEdge(self, v1, v2, w):\n",
        "    # adding two vertex according to the edge list, undirected edge\n",
        "    self.adjacent[v1].append(v2)\n",
        "    self.adjacent[v2].append(v1)\n",
        "\n",
        "\n",
        "  def BFS(self, s, n):\n",
        "    # In this BFS implementation, I use queue for ease of implementation\n",
        "    queue = []\n",
        "    visit = []\n",
        "    output = []\n",
        "\n",
        "    # Initialize the visit list by filling array visit as False (not visited)\n",
        "    visit = [False] * (max(self.adjacent) + 1)\n",
        "\n",
        "    # Start appending the start element\n",
        "    queue.append(s)\n",
        "    visit[s] = True\n",
        "\n",
        "    # Loop through the queue, dequeue, marked visit, and print the current node.\n",
        "    # If the end node has been reached, return from the loop\n",
        "    # Add any unvisited node adjacent to the current node.\n",
        "    while queue:\n",
        "      current = queue.pop(0)\n",
        "      output.append('N_' + str(current))\n",
        "\n",
        "      if current == n:\n",
        "        return output\n",
        "\n",
        "      for i in self.adjacent[current]:\n",
        "        if not visit[i]:\n",
        "          queue.append(i)\n",
        "          visit[i] = True\n",
        "\n",
        "    return None\n",
        "\n",
        "  def main(self,edge_list, node_id):\n",
        "    bfs = BFS()\n",
        "\n",
        "  # Add edges to the graph\n",
        "  # Add edges from the edge list txt file to the graph\n",
        "    bfs.readEdge(edge_list)\n",
        "\n",
        "    # Get the last item in the list\n",
        "    file = open(node_id, 'r')\n",
        "    data = file.readlines()\n",
        "    file.close()\n",
        "\n",
        "    firstRow = data[0]\n",
        "    s = int(firstRow[2:3])\n",
        "    lastRow = data[-1]\n",
        "    e = int(lastRow[2:5].rstrip(','))\n",
        "\n",
        "    # BFS output with time elapsed to measure performance\n",
        "    start = time.time()\n",
        "    output = bfs.BFS(s, e)\n",
        "    print(\"BFS:\", output)\n",
        "    print(\"Length:\", len(output))\n",
        "    end = time.time()\n",
        "    print(\"Elapse time:\", end - start, 'seconds')\n",
        "\n",
        "\n",
        "# Main method\n",
        "if __name__ == '__main__':\n",
        "  bfs = BFS()\n",
        "  path_edge = '/content/drive/My Drive/Colab Notebooks/TestCase_03_EdgeList.txt'\n",
        "  path_id = '/content/drive/My Drive/Colab Notebooks/TestCase_03_NodeID.csv'\n",
        "  bfs.main(path_edge, path_id)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Depth-First Search Report\n",
        "\n",
        "Design:\n",
        "*   Different from Breadth-First Search, Depth-First Search (DFS) traverse each node and its adjacent nodes one by one rather than all possible edges, then backtrack if hit a dead-end. To simulate this behavior, I push a node on a stack, pop it and push all of it adjacent nodes on to the stack, then repeat this process until the entire stack is empty or until the goal node has been reached. If a node does not have any adjacent node, DFS can backtrack to its previous parent and continue on a different path.\n",
        "\n",
        "Implementation:\n",
        "*   For this implementation of DFS, I use a stack data structure for the search. This is because of its Last In First Out principle that will allow backtracking to its previous parent node if the current node does not have any direct adjacent node to it. It is also fairly simple to implement as it is pretty much similar to a queue implementation in BFS but pop at the end (top of the stack) rather than the first element.\n",
        "\n",
        "*  First, similar to BFS I also initialize an adjacency list using the Python built in defaultdict library. For each node value I can assign a key list of adjacent nodes as edge to that node.\n",
        "\n",
        "*   I then also initialize three empty arrays: a stack, a visit, and an output array. The visit array is filled with False boolean value to indicate no node has been visited yet. I then push the start node onto the stack, pop it to reveal the adjacent nodes and add the start node to the output array for path display. This process is repeat until the end node is pop off the stack or the stack is empty."
      ],
      "metadata": {
        "id": "mkfmNUMmAKDl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Depth-first search implementation\n",
        "import time\n",
        "from collections import defaultdict\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "#class DFS - Depth-first search using stack\n",
        "class DFS:\n",
        "  def __init__(self):\n",
        "    # default dictionary to store the graph info\n",
        "    self.adjacent = defaultdict(list)\n",
        "\n",
        "    # A readEdge function that reads in the edges from the edge list along with the weight as input\n",
        "  def readEdge(self, fname):\n",
        "      file = open(fname, 'r')\n",
        "\n",
        "      for line in file:\n",
        "          data = line.strip().split(',')\n",
        "          v1, v2, w = int(data[0].removeprefix('N_')), int(data[1].removeprefix('N_')), float(data[2])\n",
        "          self.addEdge(v1, v2, w)\n",
        "\n",
        "      file.close()\n",
        "\n",
        "    # add edge function\n",
        "  def addEdge(self, v1, v2, w):\n",
        "    # adding two vertex according to the edge list, undirected edge\n",
        "    self.adjacent[v1].append(v2)\n",
        "    self.adjacent[v2].append(v1)\n",
        "\n",
        "  def DFS(self, s, n):\n",
        "    # In this DFS implementation, I went with stack\n",
        "    stack = []\n",
        "    visit = []\n",
        "    output = []\n",
        "\n",
        "    # Initialize the visit list by filling array visit as False (not visited)\n",
        "    visit = [False] * (max(self.adjacent) + 1)\n",
        "    stack.append(s)\n",
        "\n",
        "    # Iterate through the stack, pop, marked visited and print the current node\n",
        "    # If the goal node has been reached, return\n",
        "    # Add any unvisited node adjacent to the current node to the stack\n",
        "    while stack:\n",
        "      current = stack.pop()\n",
        "      if not visit[current]:\n",
        "        output.append('N_' + str(current))\n",
        "        visit[current] = True\n",
        "\n",
        "        if current == n:\n",
        "          return output\n",
        "\n",
        "        for i in self.adjacent[current]:\n",
        "          if not visit[i]:\n",
        "            stack.append(i)\n",
        "\n",
        "    return None\n",
        "\n",
        "  def main(self, edge_list, node_id):\n",
        "    dfs = DFS()\n",
        "\n",
        "    # Add edges from the edge list txt file to the graph\n",
        "    dfs.readEdge(edge_list)\n",
        "\n",
        "    # Get the last item in the list\n",
        "    file = open(node_id, 'r')\n",
        "    data = file.readlines()\n",
        "    file.close()\n",
        "\n",
        "    firstRow = data[0]\n",
        "    s = int(firstRow[2:3])\n",
        "    lastRow = data[-1]\n",
        "    e = int(lastRow[2:5].rstrip(','))\n",
        "\n",
        "\n",
        "    # DFS output with time elapsed to measure performance\n",
        "    start = time.time()\n",
        "    output = dfs.DFS(s, e)\n",
        "    print(\"DFS:\", output)\n",
        "    print(\"Length:\", len(output))\n",
        "    end = time .time()\n",
        "    print(\"Elapse time:\", end - start, 'seconds')\n",
        "\n",
        "# Main method\n",
        "if __name__ == '__main__':\n",
        "  dfs = DFS()\n",
        "  path_edge = '/content/drive/My Drive/Colab Notebooks/TestCase_02_EdgeList.txt'\n",
        "  path_id = '/content/drive/My Drive/Colab Notebooks/TestCase_02_NodeID.csv'\n",
        "  dfs.main(path_edge, path_id)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1iLT0lebvnIe",
        "outputId": "e5e530f8-0c1e-4b6d-c977-c421d7757eae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DFS: ['N_0', 'N_10', 'N_11', 'N_1', 'N_2', 'N_12', 'N_3', 'N_13', 'N_23', 'N_22', 'N_24', 'N_25', 'N_26', 'N_15', 'N_16', 'N_6', 'N_5', 'N_34', 'N_35', 'N_36', 'N_37', 'N_38', 'N_48', 'N_27', 'N_17', 'N_18', 'N_8', 'N_9', 'N_19', 'N_29', 'N_39', 'N_7', 'N_28', 'N_46', 'N_47', 'N_56', 'N_57', 'N_58', 'N_59', 'N_49', 'N_67', 'N_68', 'N_78', 'N_77', 'N_87', 'N_86', 'N_85', 'N_84', 'N_74', 'N_94', 'N_83', 'N_73', 'N_93', 'N_92', 'N_95', 'N_96', 'N_76', 'N_75', 'N_65', 'N_97', 'N_88', 'N_98', 'N_79', 'N_89', 'N_99']\n",
            "Length: 65\n",
            "Elapse time: 0.00036716461181640625 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A* Report\n",
        "\n",
        "Design:\n",
        "\n",
        "*   A* Search is a graph traversal technique that, unlike BFS or DFS, relied the use of weighted graph and heuristic function to achieve the shortest, most optimal path from a start node to the goal node. For this A* algorithm, I utilize both the coordination and weighted graph in the provided nodeID file and the edgeList file for the purpose of calculating the heuristic function along with the weight of each edge in edgeList.\n",
        "\n",
        "*   The algorithm itself will have two data set: open and closed set that will keep track of nodes visit. It will also have a g(n) function that calculate the cost from the start node to the current node, necessary to calculate the f(n) fucntion that will guide the algorithm to choose the lowest cost node for the shortest path. Finally, if the goal node is reached, it will reconstruct the optimal path from the start node to the goal node.\n",
        "\n",
        "Implementation:\n",
        "\n",
        "*   There are two heuristic functions that I chose for the A* algorithm: Manhattan Distance and Euclidean Distance. Both are admissible heuristic function that capable of finding the shortest path from start to end. The reason why I choose Euclidean is because I want to see the effect of a multi-direction distance in a graph that only permits movement of 4 directions.\n",
        "\n",
        "*   First, I initialized two adjacency list, node_id and edge_list. These adjacency lists will then be used to store two things: node_id will store all of the nodes inside nodeID file as value and their coordinations as keys, while edge_list will store the nodes as value and its associated edge and weights as keys, and it goes both way assuming this is an undirected graph.\n",
        "\n",
        "*   I then create a heuristic_func that calculate the heuristic function using the coordination of the nodes in node_id. In both implementation the heuristic is calculated in respect to the distance formulas I discussed previously.\n",
        "\n",
        "*   In A* algorithm, I initialized two sets: open_set and closed_set. open_set is used to store the visited node whose neighbor have not been visited so it appends the start node at initialization, while the closed_set store the visited node with all neighbors visited. I also initialized two dictionaries: the g_func dictionaries to keep track of the accumulated cost from start node to current node, and a prev_node dictionaries that assign each neighbor nodes to its previous parent node.\n",
        "\n",
        "*   I then iterate through the open_set, calculating the f(n) cost for each of the node inisde the open_set and set the lowest f(n) value to the current node. If there is no path, I simply return None, and if the current node is the end node, I reconstruct and return the optimal path from start to end node. Otherwise, if they are in neither of the sets, I retrieve the neighbors of the current node, add them to the open_set, calculate their g(n) cost, and set the current node as their parent node. If they are (indication that they have been visited), I simply update their g(n) cost if higher than current node's g(n) cost and set the current node as their parents. If they are in the closed_set, however, it means that they have been visited and I am backtracking, then I simply add them back to the open_set and repeat the process.\n",
        "\n",
        "*   The reconstruct_path function works by retrieving the prev_node dictionary and iterates as long as the current node n is not the start node s. Inside the loop, the current node n is appended to the reconstruct_path list. The value of n is then updated to its parent node. Once the loop exits, the start node s is appended and the reconstruct_path list is return."
      ],
      "metadata": {
        "id": "BGb4wLiENdlf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A* implementation - Manhattan distance\n",
        "from collections import defaultdict\n",
        "import math\n",
        "import time\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# A* implementation\n",
        "class A_Star:\n",
        "  # Initialization\n",
        "  def __init__(self):\n",
        "    self.node_id = defaultdict(list)\n",
        "    self.edge_list = defaultdict(list)\n",
        "\n",
        "  # read_node_id function - read nodes and coordinations from the nodeID file\n",
        "  # Set the coordination and node name into the node_id adjacency list\n",
        "  def read_node_id(self, fname):\n",
        "    file = open(fname, 'r')\n",
        "    for line in file:\n",
        "      node = line.strip().split(',')\n",
        "      node_name = node[0]\n",
        "      x, y = map(int, node[1:])\n",
        "      self.node_id[node_name] = (x, y)\n",
        "\n",
        "    file.close()\n",
        "\n",
        "  # read_edge_list function - read edges and weights from the edgeList file\n",
        "  # Set each node and its associated weights and edges to the edge_list adjacency list\n",
        "  def read_edge_list(self, fname):\n",
        "    file = open(fname, 'r')\n",
        "    for line in file:\n",
        "      edge = line.strip().split(',')\n",
        "      v1, v2, w = edge[0], edge[1], float(edge[2])\n",
        "      self.edge_list[v1].append((v2, w))\n",
        "      self.edge_list[v2].append((v1, w))\n",
        "\n",
        "    file.close()\n",
        "\n",
        "  # get_neighbors - return the edges and weights of a single node v\n",
        "  def get_neighbors(self, v):\n",
        "    return self.edge_list[v]\n",
        "\n",
        "  # heuristic_func - calculate the heuristic\n",
        "  def heuristic_func(self, v1, v2):\n",
        "    x1, y1 = self.node_id[v1]\n",
        "    x2, y2 = self.node_id[v2]\n",
        "\n",
        "    h = (abs(x1 - x2) + abs(y1 - y2))\n",
        "    return h\n",
        "\n",
        "  # reconstruct_path - return the optimal path after the end node has been reached\n",
        "  # Because nodes are being appended to prev_node from bottom up, the output must be return inversed\n",
        "  def reconstruct_path(self, prev_node, s, n):\n",
        "    reconstruct_path = []\n",
        "    while prev_node[n] != n:\n",
        "      reconstruct_path.append(n)\n",
        "      n = prev_node[n]\n",
        "\n",
        "    reconstruct_path.append(s)\n",
        "    return reconstruct_path[::-1]\n",
        "\n",
        "   # a_star - the search algorithm of this\n",
        "  def a_star(self, s, e):\n",
        "    # Initialize two sets\n",
        "    # open_set to store the visited node whose neighbors are not visited\n",
        "    # closed_set to store the node with all neighbors visited\n",
        "    open_set = set([s])\n",
        "    closed_set = set()\n",
        "\n",
        "    # g_func or g(n) - contains the accumulated distance from the start node to any other node\n",
        "    g_func = {s: 0.0}\n",
        "\n",
        "    # prev_node dictionary to store the previous node (or parent) of all considered nodes\n",
        "    prev_node = {s: s}\n",
        "\n",
        "    # Until the set is empty\n",
        "    while open_set:\n",
        "      # Set the current node to None\n",
        "      current_n = None\n",
        "      # Iterate through the open_set to find the least cost node\n",
        "      for visited in open_set:\n",
        "        # f(v) = g(v) + h(v)\n",
        "        f_func_v = g_func[visited] + self.heuristic_func(visited, e)\n",
        "        if current_n == None or f_func_v < g_func[current_n] + self.heuristic_func(current_n, e):\n",
        "          # Assign v to n if n is either none or the f(v) is better than f(n) (more optimal)\n",
        "          current_n = visited\n",
        "      # Return None if there is no path\n",
        "      if current_n == None:\n",
        "        return None\n",
        "      # Reconstruct if the current node is the end node\n",
        "      if current_n == e:\n",
        "        return self.reconstruct_path(prev_node, s, current_n)\n",
        "\n",
        "      # for all neighbors and their weight of the current node\n",
        "      for (n2, w) in self.get_neighbors(current_n):\n",
        "        # if they have not been visited (not in bot set)\n",
        "        if n2 not in open_set and n2 not in closed_set:\n",
        "          # Add them to the open_set, await to inspect their neighbor\n",
        "          # Set n as the previous parent node of the neighbors node for optimal path display\n",
        "          # Calulate the new cost from the start node to the neighbor node\n",
        "          open_set.add(n2)\n",
        "          prev_node[n2] = current_n\n",
        "          g_func[n2] = g_func[current_n] + w\n",
        "        # if they are\n",
        "        else:\n",
        "          # Check if it is faster to visit the current node than the neighbor nodes\n",
        "          # Calculate the new cost from the start node to the neighbor node and set n as the parent node\n",
        "          if g_func[current_n] + w < g_func[n2]:\n",
        "            prev_node[n2] = current_n\n",
        "            g_func[n2] = g_func[current_n] + w\n",
        "            # Re-visit node if a better path has been found\n",
        "            if n2 in closed_set:\n",
        "              closed_set.remove(n2)\n",
        "              open_set.add(n2)\n",
        "\n",
        "      # Finally, marked the current node as visited by adding it to the closed_set\n",
        "      open_set.remove(current_n)\n",
        "      closed_set.add(current_n)\n",
        "\n",
        "    return None\n",
        "\n",
        "  # Main method\n",
        "  def main(self):\n",
        "    a = A_Star()\n",
        "    node_id_file_path = '/content/drive/My Drive/Colab Notebooks/TestCase_03_NodeID.csv'\n",
        "    edge_list_file_path = '/content/drive/My Drive/Colab Notebooks/TestCase_03_EdgeList.txt'\n",
        "    a.read_node_id(node_id_file_path)\n",
        "    a.read_edge_list(edge_list_file_path)\n",
        "\n",
        "    file = open(node_id_file_path, 'r')\n",
        "    data = file.readlines()\n",
        "    file.close()\n",
        "\n",
        "    firstRow = data[0]\n",
        "    s = firstRow[:3]\n",
        "    lastRow = data[-1]\n",
        "    e = lastRow[:5].rstrip(',')\n",
        "\n",
        "    start = time.time()\n",
        "    output = a.a_star(s, e)\n",
        "    print('A*:', output)\n",
        "    print('Length:', len(output))\n",
        "    end = time.time()\n",
        "\n",
        "    print('Elapse time: ', end - start, 'seconds')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  a = A_Star()\n",
        "  a.main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAyooMXU0gEB",
        "outputId": "bf308783-7fd7-46b2-f6f8-c34d5a8bc00e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A*: ['N_0', 'N_100', 'N_200', 'N_300', 'N_301', 'N_302', 'N_402', 'N_502', 'N_602', 'N_603', 'N_503', 'N_403', 'N_303', 'N_203', 'N_204', 'N_205', 'N_206', 'N_207', 'N_107', 'N_108', 'N_109', 'N_110', 'N_111', 'N_112', 'N_212', 'N_213', 'N_113', 'N_114', 'N_115', 'N_116', 'N_117', 'N_17', 'N_18', 'N_19', 'N_20', 'N_21', 'N_121', 'N_122', 'N_123', 'N_124', 'N_125', 'N_225', 'N_226', 'N_126', 'N_127', 'N_227', 'N_228', 'N_128', 'N_129', 'N_130', 'N_230', 'N_330', 'N_331', 'N_332', 'N_333', 'N_233', 'N_234', 'N_235', 'N_135', 'N_35', 'N_36', 'N_37', 'N_38', 'N_138', 'N_139', 'N_140', 'N_40', 'N_41', 'N_42', 'N_142', 'N_242', 'N_243', 'N_244', 'N_144', 'N_145', 'N_45', 'N_46', 'N_146', 'N_147', 'N_148', 'N_149', 'N_249', 'N_349', 'N_449', 'N_450', 'N_550', 'N_551', 'N_451', 'N_351', 'N_352', 'N_252', 'N_253', 'N_153', 'N_53', 'N_54', 'N_55', 'N_155', 'N_156', 'N_157', 'N_158', 'N_159', 'N_59', 'N_60', 'N_61', 'N_62', 'N_162', 'N_163', 'N_164', 'N_165', 'N_65', 'N_66', 'N_67', 'N_167', 'N_168', 'N_169', 'N_69', 'N_70', 'N_71', 'N_72', 'N_73', 'N_74', 'N_75', 'N_76', 'N_77', 'N_177', 'N_277', 'N_377', 'N_376', 'N_476', 'N_477', 'N_577', 'N_578', 'N_579', 'N_679', 'N_680', 'N_681', 'N_682', 'N_582', 'N_482', 'N_382', 'N_383', 'N_384', 'N_484', 'N_485', 'N_486', 'N_586', 'N_686', 'N_687', 'N_688', 'N_788', 'N_789', 'N_790', 'N_791', 'N_691', 'N_692', 'N_693', 'N_694', 'N_794', 'N_795', 'N_796', 'N_896', 'N_897', 'N_997', 'N_998', 'N_999']\n",
            "Length: 165\n",
            "Elapse time:  0.012732267379760742 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A* implementation - Euclidean distance\n",
        "from collections import defaultdict\n",
        "import math\n",
        "import time\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# A* implementation\n",
        "class A_Star:\n",
        "  # Initialization\n",
        "  def __init__(self):\n",
        "    self.node_id = defaultdict(list)\n",
        "    self.edge_list = defaultdict(list)\n",
        "\n",
        "  # read_node_id function - read nodes and coordinations from the nodeID file\n",
        "  # Set the coordination and node name into the node_id adjacency list\n",
        "  def read_node_id(self, fname):\n",
        "    file = open(fname, 'r')\n",
        "    for line in file:\n",
        "      node = line.strip().split(',')\n",
        "      node_name = node[0]\n",
        "      x, y = map(int, node[1:])\n",
        "      self.node_id[node_name] = (x, y)\n",
        "\n",
        "    file.close()\n",
        "\n",
        "  # read_edge_list function - read edges and weights from the edgeList file\n",
        "  # Set each node and its associated weights and edges to the edge_list adjacency list\n",
        "  def read_edge_list(self, fname):\n",
        "    file = open(fname, 'r')\n",
        "    for line in file:\n",
        "      edge = line.strip().split(',')\n",
        "      v1, v2, w = edge[0], edge[1], float(edge[2])\n",
        "      self.edge_list[v1].append((v2, w))\n",
        "      self.edge_list[v2].append((v1, w))\n",
        "\n",
        "    file.close()\n",
        "\n",
        "  # get_neighbors - return the edges and weights of a single node v\n",
        "  def get_neighbors(self, v):\n",
        "    return self.edge_list[v]\n",
        "\n",
        "  # heuristic_func - calculate the heuristic\n",
        "  def heuristic_func(self, v1, v2):\n",
        "    x1, y1 = self.node_id[v1]\n",
        "    x2, y2 = self.node_id[v2]\n",
        "\n",
        "    h = math.sqrt((x1-x2)**2 + (y1-y2)**2)\n",
        "    return h\n",
        "\n",
        "  # reconstruct_path - return the optimal path after the end node has been reached\n",
        "  # Because nodes are being appended to prev_node from bottom up, the output must be return inversed\n",
        "  def reconstruct_path(self, prev_node, s, n):\n",
        "    reconstruct_path = []\n",
        "    while prev_node[n] != n:\n",
        "      reconstruct_path.append(n)\n",
        "      n = prev_node[n]\n",
        "\n",
        "    reconstruct_path.append(s)\n",
        "    return reconstruct_path[::-1]\n",
        "\n",
        "  # a_star - the search algorithm of this\n",
        "  def a_star(self, s, e):\n",
        "    # Initialize two sets\n",
        "    # open_set to store the visited node whose neighbors are not visited\n",
        "    # closed_set to store the node with all neighbors visited\n",
        "    open_set = set([s])\n",
        "    closed_set = set()\n",
        "\n",
        "    # g_func or g(n) - contains the accumulated distance from the start node to any other node\n",
        "    g_func = {s: 0.0}\n",
        "\n",
        "    # prev_node dictionary to store the previous node (or parent) of all considered nodes\n",
        "    prev_node = {s: s}\n",
        "\n",
        "    # Until the set is empty\n",
        "    while open_set:\n",
        "      # Set the current node to None\n",
        "      current_n = None\n",
        "      # Iterate through the open_set to find the least cost node\n",
        "      for visited in open_set:\n",
        "        # f(v) = g(v) + h(v)\n",
        "        f_func_v = g_func[visited] + self.heuristic_func(visited, e)\n",
        "        if current_n == None or f_func_v < g_func[current_n] + self.heuristic_func(current_n, e):\n",
        "          # Assign v to n if n is either none or the f(v) is better than f(n) (more optimal)\n",
        "          current_n = visited\n",
        "      # Return None if there is no path\n",
        "      if current_n == None:\n",
        "        return None\n",
        "      # Reconstruct if the current node is the end node\n",
        "      if current_n == e:\n",
        "        return self.reconstruct_path(prev_node, s, current_n)\n",
        "\n",
        "      # for all neighbors and their weight of the current node\n",
        "      for (n2, w) in self.get_neighbors(current_n):\n",
        "        # if they have not been visited (not in bot set)\n",
        "        if n2 not in open_set and n2 not in closed_set:\n",
        "          # Add them to the open_set, await to inspect their neighbor\n",
        "          # Set n as the previous parent node of the neighbors node for optimal path display\n",
        "          # Calulate the new cost from the start node to the neighbor node\n",
        "          open_set.add(n2)\n",
        "          prev_node[n2] = current_n\n",
        "          g_func[n2] = g_func[current_n] + w\n",
        "        # if they are\n",
        "        else:\n",
        "          # Check if it is faster to visit the current node than the neighbor nodes\n",
        "          # Calculate the new cost from the start node to the neighbor node and set n as the parent node\n",
        "          if g_func[current_n] + w < g_func[n2]:\n",
        "            prev_node[n2] = current_n\n",
        "            g_func[n2] = g_func[current_n] + w\n",
        "            # Re-visit node if a better path has been found\n",
        "            if n2 in closed_set:\n",
        "              closed_set.remove(n2)\n",
        "              open_set.add(n2)\n",
        "\n",
        "      # Finally, marked the current node as visited by adding it to the closed_set\n",
        "      open_set.remove(current_n)\n",
        "      closed_set.add(current_n)\n",
        "\n",
        "    return None\n",
        "\n",
        "  # Main method\n",
        "  def main(self):\n",
        "    a = A_Star()\n",
        "    node_id_file_path = '/content/drive/My Drive/Colab Notebooks/TestCase_03_NodeID.csv'\n",
        "    edge_list_file_path = '/content/drive/My Drive/Colab Notebooks/TestCase_03_EdgeList.txt'\n",
        "    a.read_node_id(node_id_file_path)\n",
        "    a.read_edge_list(edge_list_file_path)\n",
        "\n",
        "    file = open(node_id_file_path, 'r')\n",
        "    data = file.readlines()\n",
        "    file.close()\n",
        "\n",
        "    firstRow = data[0]\n",
        "    s = firstRow[:3]\n",
        "    lastRow = data[-1]\n",
        "    e = lastRow[:5].rstrip(',')\n",
        "\n",
        "    start = time.time()\n",
        "    output = a.a_star(s, e)\n",
        "    print('A*:', output)\n",
        "    print('Length:', len(output))\n",
        "    end = time.time()\n",
        "\n",
        "    print('Elapse time: ', end - start, 'seconds')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  a = A_Star()\n",
        "  a.main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoof3BD2vtK4",
        "outputId": "9ea1d8ed-67dc-4521-eb61-046be4e897e5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A*: ['N_0', 'N_100', 'N_200', 'N_300', 'N_301', 'N_302', 'N_402', 'N_502', 'N_602', 'N_603', 'N_503', 'N_403', 'N_303', 'N_203', 'N_204', 'N_205', 'N_206', 'N_207', 'N_107', 'N_108', 'N_109', 'N_110', 'N_111', 'N_112', 'N_212', 'N_213', 'N_113', 'N_114', 'N_115', 'N_116', 'N_117', 'N_17', 'N_18', 'N_19', 'N_20', 'N_21', 'N_121', 'N_122', 'N_123', 'N_124', 'N_125', 'N_225', 'N_226', 'N_126', 'N_127', 'N_227', 'N_228', 'N_128', 'N_129', 'N_130', 'N_230', 'N_330', 'N_331', 'N_332', 'N_333', 'N_233', 'N_234', 'N_235', 'N_135', 'N_35', 'N_36', 'N_37', 'N_38', 'N_138', 'N_139', 'N_140', 'N_40', 'N_41', 'N_42', 'N_142', 'N_242', 'N_243', 'N_244', 'N_144', 'N_145', 'N_45', 'N_46', 'N_146', 'N_147', 'N_148', 'N_149', 'N_249', 'N_349', 'N_449', 'N_450', 'N_550', 'N_551', 'N_451', 'N_351', 'N_352', 'N_252', 'N_253', 'N_153', 'N_53', 'N_54', 'N_55', 'N_155', 'N_156', 'N_157', 'N_158', 'N_159', 'N_59', 'N_60', 'N_61', 'N_62', 'N_162', 'N_163', 'N_164', 'N_165', 'N_65', 'N_66', 'N_67', 'N_167', 'N_168', 'N_169', 'N_69', 'N_70', 'N_71', 'N_72', 'N_73', 'N_74', 'N_75', 'N_76', 'N_77', 'N_177', 'N_277', 'N_377', 'N_376', 'N_476', 'N_477', 'N_577', 'N_578', 'N_579', 'N_679', 'N_680', 'N_681', 'N_682', 'N_582', 'N_482', 'N_382', 'N_383', 'N_384', 'N_484', 'N_485', 'N_486', 'N_586', 'N_686', 'N_687', 'N_688', 'N_788', 'N_789', 'N_790', 'N_791', 'N_691', 'N_692', 'N_693', 'N_694', 'N_794', 'N_795', 'N_796', 'N_896', 'N_897', 'N_997', 'N_998', 'N_999']\n",
            "Length: 165\n",
            "Elapse time:  0.026561498641967773 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performance Comparison Report\n",
        "\n",
        "In this report, I will compare the three algorithms' performance based on two metrics: time (in seconds) takes to complete the search and the amount of nodes taken and discuss on which one is most suitable for this kind of problems.\n",
        "\n",
        "BFS Performance:\n",
        "\n",
        "*   Case 1:\n",
        "*   Nodes taken: 25\n",
        "*   Average time taken(s): 0.000214\n",
        "\n",
        "\n",
        "*   Case 2:\n",
        "*   Nodes taken: 74\n",
        "*   Average time taken(s):: 0.00254\n",
        "\n",
        "\n",
        "*   Case 3:\n",
        "*   Nodes taken: 977\n",
        "*   Average time taken(s):: 0.00242\n",
        "\n",
        "DFS Performance:\n",
        "\n",
        "*   Case 1:\n",
        "*   Nodes taken: 14\n",
        "*   Average time taken(s):: 0.000223\n",
        "\n",
        "\n",
        "*   Case 2:\n",
        "*   Nodes taken: 65\n",
        "*   Average time taken(s): 0.00106\n",
        "\n",
        "\n",
        "*   Case 3:\n",
        "*   Nodes taken: 741\n",
        "*   Average time taken(s): 0.00352\n",
        "\n",
        "A* Performance:\n",
        "\n",
        "Manhattan:\n",
        "\n",
        "\n",
        "*   Case 1:\n",
        "*   Nodes taken: 9\n",
        "*   Average time taken(s): 0.00039\n",
        "\n",
        "\n",
        "*   Case 2:\n",
        "*   Nodes taken: 21\n",
        "*   Average time taken(s): 0.00120\n",
        "\n",
        "\n",
        "*   Case 3:\n",
        "*   Nodes taken: 165\n",
        "*   Average time taken(s): 0.01722\n",
        "\n",
        "\n",
        "Euclidean:\n",
        "\n",
        "*   Case 1:\n",
        "*   Nodes taken: 9\n",
        "*   Average time taken(s): 0.00041\n",
        "\n",
        "\n",
        "*   Case 2:\n",
        "*   Nodes taken: 21\n",
        "*   Average time taken(s): 0.00117\n",
        "\n",
        "\n",
        "*   Case 3:\n",
        "*   Nodes taken: 165\n",
        "*   Average time taken(s): 0.0252\n",
        "\n",
        "\n",
        "Based on the performance comparison between three algorithms, it is very apparent that A* search algorithm is the best traversal algorithm by far. Possibly due to the limited sample size, average time completion between three algorithms across all three cases are similar, or one could even say that it is advantageous for A* algorithm because it doesn't sacrifice runtime to find the shortest path from start to finish. Nodes taken in A* reduces the number of nodes taken by an estimated 64% compare to BFS and 36% compares to DFS in case 1, 71% for BFS and 68% for DFS in case 2, and a whooping 83% for BFS and 77% for DFS in case 3. The larger the sample size, the better A* algorithm performs compare to the other two algorithms at relatively the same average time.\n",
        "\n",
        "In the case of why I choose to implement Manhattan Distance and Euclidean Distance as the heuristic function for my A* search algorithm, it is because one heuristic is more suitable than the others and I want to see the effects of that on A*. Both are admissible in these cases and should return the same optimal path as each other, which basically will always be better than the uninformed search algorithms. However, in a state-space graph that only permit a movement of 4 directions, Euclidean Distance would still return the shortest path but will take longer to run, and this can be reflect in the average time taken in case 3. No matter how many time I run the program, Euclidean A* always perform around 0.01 slower than Manhattan A*, and I imagine this would become more apparent on a larger sample size.\n",
        "\n",
        "In conclusion, given the additional information and context, informed search algorithms like A* search can outperform any uninformed search in terms of most optimal path.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8soY_IRYYb0z"
      }
    }
  ]
}